---
title: "Dia-04"
---

```{r, echo=FALSE}

knitr::opts_chunk$set(fig.align = 'center', out.width="100%", fig.retina = 2, warning = FALSE, message = FALSE)

pacman::p_load(tidyverse, lme4, mgcv, refund, face, fda, rgl, fields, refund.shiny, janitor)

```

# Modelos lineares funcionais {secao-4}

Os modelos lineares funcionais são uma classe de modelos estatísticos que lidam com dados funcionais, ou seja, observações que são representadas como funções contínuas ao invés de valores numéricos isolados. Esses modelos são amplamente utilizados para análise de dados funcionais em várias áreas, como biologia, economia, engenharia e ciências da saúde.

A ideia básica por trás dos modelos lineares funcionais é estender a estrutura dos modelos lineares tradicionais para acomodar dados funcionais. Em um modelo linear funcional, a variável de resposta é modelada como uma combinação linear de funções base, onde os coeficientes de regressão indicam o efeito das funções base na resposta. Essas funções base podem ser pré-determinadas, como funções polinomiais ou splines, ou podem ser obtidas de forma adaptativa a partir dos próprios dados, por exemplo, usando a Análise de Componentes Principais Funcionais (fPCA).

Ajustar um modelo linear funcional envolve estimar os coeficientes de regressão e possivelmente outros parâmetros do modelo, como a variância do erro. Diversas técnicas de estimação estão disponíveis para modelos lineares funcionais, incluindo mínimos quadrados ponderados, estimação por máxima verossimilhança e métodos baseados em penalização.

Uma vantagem dos modelos lineares funcionais é que eles permitem modelar a estrutura temporal dos dados e capturar a variabilidade e dependência funcional ao longo do tempo. Isso torna esses modelos particularmente adequados para dados longitudinais ou séries temporais, onde a variação e a relação entre as observações podem mudar ao longo do tempo.

Em resumo, os modelos lineares funcionais são uma poderosa ferramenta estatística para análise de dados funcionais, permitindo modelar e interpretar relações entre variáveis em um contexto funcional e temporal.

# Tópicos de hoje:

-   Regressão de escalar em função - SoF (pfr)

-   Regressão de componentes principais funcionais (FPC)

-   Modelo linear funcional com base restrita

-   Gráficos interativos (plot_shiny) para regressão de escalar em função

-   Função em escalar - FoS (pffr)

-   Função em função - FoF (pffr)

-   Modelos lineares funcionais simultâneos

\[Código fornecido por cortesia de Arnab Maity\]

## 1 Scalar-on-function regression model

"Scalar-on-function regression model" pode ser traduzido como "modelo de regressão escalar em função". Nesse contexto, "scalar" se refere a um valor único, enquanto "function" se refere a uma função matemática que pode variar de acordo com uma variável independente. Portanto, um "scalar-on-function regression model" é um modelo de regressão que visa prever um valor único (escalar) com base em uma função variável.

```{r, warning=FALSE, message=FALSE}

marathon_results_2017 <-readr::read_csv("marathon_results_2017.csv")


marathon_df <- marathon_results_2017 %>% 
dplyr::select(-c(`...1`,
            Bib,City,
            State,
            Country,
            Citizen,
            `...10`,
            Division,
            Gender,
            Overall,
            `Proj Time`)) %>% 
  janitor::clean_names()

mutate_seconds <- function(x){
  lubridate::hour(x)* 3600 + lubridate::minute(x) * 60 + lubridate::second(x) *1
}
  

 marathon_df <- 
   marathon_df %>% 
        drop_na() %>% 
        mutate(
          across(starts_with(c("x","half")), lubridate::hms),
          across(starts_with(c("x","half","pace", "official_time")), mutate_seconds),
          `5` = (5000/ `x5k`)*3.6,
          `10` = (10000/ `x10k`)*3.6,
          `15` = (15000/ `x15k`)*3.6,
          `20` = (20000/ `x20k`)*3.6,
          `21` = (21000/ half)*3.6,
          `25` = (25000/ `x25k`)*3.6,
          `30` = (30000/ `x30k`)*3.6,
          `35` = (35000/ `x35k`)*3.6,
          `40` = (40000/ `x40k`)*3.6,
          `42` = (42000/ official_time)*3.6
            ) %>% 
   rename(
     names = name
   )
 
 
marathon_df %>% 
  dplyr::slice(1:50) %>% 
  pivot_longer(cols = 15:24) %>% 
  mutate(
    name = as.numeric(name)
  ) %>% 
  group_by(name) %>% 
  ggplot(aes(name,value, group = names, color = m_f))+
  geom_line(alpha = 0.7, color = "grey")+
  #geom_point(color = "black", alpha = 0.7)+
  ylab("Velocidade Km/h")+
  xlab("Km de maratona")+
  ggtitle("Maratona - Velocidade")
```

Pergunta de interesse: Existe alguma relação entre o tempo total decorrido e o ritmo da corrida (perfis de milhas por minuto)?

Agora podemos responder a essas perguntas usando o modelo de regressão linear funcional com resposta escalar e covariável funcional! (SoF)

Lembrando:

$$
Y_i = \mu_Y + \int X_i(t) \beta(t) dt + \epsilon_i,
$$

onde Xi é modelado usando fPCA, $X_i = \mu(t) + \sum_{i=1}^{n} \sum_{k=1}^{\infty} \xi_{ik}\phi_{k}(t)t)$

Lembrando que fPCA se refere à Análise de Componentes Principais Funcionais (Functional Principal Component Analysis) e $\mu(t)$ é a média da função, ξᵢₖ são os coeficientes de PCA e $\phi_k(t)$ são as funções de base de PCA.

## 1.1 Regressão de componentes principais funcionais (FPC)

Aqui ilustramos o ajuste de regressão linear funcional assumindo $\beta(t) = \sum_{i=1}^{n} \sum_{k=1}^{\infty} \beta_{k}\phi_{k}(t)$. Primeiro carregamos o conjunto de dados e definimos a resposta e a covariável.

### Primeiro passo

O primeiro passo da estimativa é executar o fPCA na covariável funcional usando um dos softwares que implementam o fPCA (módulo 3); por exemplo, fpca.ssvd, fpca.face e fpca.sc no pacote refund / pca.fd no pacote fda / fpca.mle no pacote fpca / PACE no Matlab.

```{r}
speed <- marathon_df %>% 
dplyr::select(15:24) %>% 
dplyr::slice(1:150) %>% 
  as.matrix()

kms <- c(5,10,15,20,21,25,30,35,40,42)

final_time <- marathon_df$official_time %>% 
  as_tibble() %>% 
  dplyr::slice(1:150) %>% 
  as.matrix()

fpca_res <- fpca.face(Y= speed ,pve = 0.97, argvals = kms, knots = 6)

#fpca_res <- fpca.sc(X, argvals = miles, pve = 0.97)

m <- length(kms)
efn <- fpca_res$efunctions*sqrt(m)
eval <- fpca_res$evalues/m
scr <- fpca_res$scores/sqrt(m)
npc <- fpca_res$npc


cbind(kms,efn) %>% 
  as_tibble() %>% 
  rename(
    pc1 = V2,
    pc2 = V3
  ) %>% 
  pivot_longer(cols = starts_with("pc")) %>% 
  group_by(kms) %>% 
  ggplot(aes(kms,value,group = name, color = name))+
  geom_line()+
  labs(x="km",y="", title = "Autofunções estimadas" )
```

```{r}
k.pc <- 1
effect <- sqrt(eval[k.pc])*efn[,k.pc]
mu_hat <- fpca_res$mu


cbind(kms,efn[,k.pc]) %>% 
  as_tibble() %>% 
  ggplot(aes(kms, V2))+
  geom_line()+
  ylim(c(-2,2))+
  labs(x="km",y="", title = "fCP-1" )


mu_hat %>% 
  as_tibble_col(column_name = "mu.hat") %>% 
  mutate(
    effect_Plus = mu.hat + effect,
    effect_less = mu.hat - effect,
    kms = kms
  ) %>% 
  pivot_longer(cols = 1:3) %>% 
  group_by(kms) %>% 
  ggplot(aes(kms, value, group = name, color = name))+
  geom_line()+
  labs(x="km",y="", title = "fCP-1")

```

(Atividade para fazer em casa) Experimente o gráfico interativo dos resultados do fPCA (plot_shiny(fpca_res)) e interprete. (Módulo 3-3)

### Passo dois

Agora, usando a matriz de escores estimados, faça uma regressão linear múltipla no vetor de respostas escalares $Y$ (tempo de conclusão). Obtenha os coeficientes estimados, $\beta_j$'s.

```{r}
out = lm(final_time ~ scr) ## Multiple linear regression
# summary(out)
beta_hat = out$coefficients
beta_hat

summary(out)

```

Uma vez que o fPCA selecionou os três primeiros componentes principais com base na porcentagem especificada da variância explicada, temos aqui três coeficientes de base correspondentes.

Agora, para reconstruir a função do coeficiente de regressão,

```{r}
beta_fn_hat = efn %*% as.matrix(beta_hat[-1], col = 1) 

cbind(kms,beta_fn_hat) %>% 
  as_tibble() %>% 
  ggplot(aes(kms,V2))+
  geom_line()+
  ylim(c(-2000,800))+
  ylab("")


```

Como podemos dar sentido ao coeficiente? Vamos nos concentrar em analisar três perfis de velocidade aleatórios:

```{r}
set.seed(12)
n.crv <- 3
n <- nrow(speed)
sel.crv <- sample(1:n, size=n.crv, replace = FALSE)

rand_speed <- t(fpca_res$Yhat[sel.crv,])

cbind(kms,rand_speed) %>% 
  as_tibble() %>% 
  pivot_longer(cols = contains("V")) %>% 
  group_by(kms) %>% 
  ggplot(aes(kms,value,group = name,color=name))+
  geom_line()+
  ylab("")


par(mfrow=c(3,3))
for(i in 1:3){
  ind <- sel.crv[i]
  demeaned <- fpca_res$Yhat[ind,]-as.vector(fpca_res$mu)
  
  matplot(kms, t(fpca_res$Yhat[sel.crv,]-t(matrix(rep(fpca_res$mu,3), nrow=10))), 
          type='l', lwd=2, lty=1, col = 'light grey',
          xlab="miles", ylab="speed (demeaned)", main="")
  lines(kms, demeaned, type='l', lwd=2, col='red')
  
  
  plot(kms, beta_fn_hat, type='l', lwd=2,
       xlab="miles", ylab = "estimated coefficient fn", main="")
  plot(kms, demeaned*beta_fn_hat,type='l', lwd=2, col='blue',
       xlab="miles", ylab = "", ylim=c(-55, 70),
       main=round(mean(demeaned*beta_fn_hat), 2))
}
```

Por último, vamos analisar a bondade de ajuste estimada.

```{r}
par(mfrow=c(1,1))
plot(final_time, out$fitted, cex=0.5, ylab="Fitted", xlab="Observed")
abline(a = 0, b = 1)


Rsq = 1-sum((out$residuals)^2)/sum((final_time- mean(final_time))^2)
Rsq
```

Existem várias funções integradas que podem ajustar um modelo linear funcional usando fPCA: a função PACE-REG no pacote Matlab PACE; a função pfr no pacote refund; a função fRegress no pacote fda.

Vantagens: computacionalmente simples e aplicável a qualquer design de amostragem. Desvantagens: forte pressuposto de que $\beta(\cdot)$ e $X(\cdot)$ estão no mesmo espaço e têm uma suavidade similar.

## 2 Modelo linear funcional com base mista

Para superar algumas limitações do método anterior, Goldsmith et al. (2011) propuseram modelar a função de coeficiente $\beta(\cdot)$) usando uma função de base truncada; no entanto, outras funções de base também são aplicáveis.

Lembre-se de que, ao modelar $X(\cdot)$ usando eigenfunções e $\beta(\cdot)$ usando funções de base pré-definidas, temos -

$$
Y_i = \alpha + \xi^T_i J \beta,
$$

onde $\boldsymbol{\xi}_i = [ \xi_{i1}, \xi_{i2}, \ldots, \xi_{iK} ]^T, J$ é uma matriz $K \times L$ com o elemento $(k,ℓ)-th$ dado por $J_{k\ell} = \int \phi_k(t)\theta_\ell(t) dt$, e $\boldsymbol{\beta} = [ \beta_1, \beta_2, \ldots, \beta_K ]^T$.

Este modelo pode ser ajustado usando a função pfr no pacote refund. (Novamente, usamos "milhas por minuto" e "tempo de conclusão" como covariável e resposta)

```{r}
X <- as.matrix(speed) # functional covariate
Y <- final_time    # scalar response


myDat <- data.frame(X, Y)

fit <- pfr(Y ~ lf(X, k = 10, bs = "cr"), method = "REML", data = myDat)
coef <- coef(fit)


cbind(coef$X.argvals, coef$value) %>% 
  as_tibble() %>% 
  ggplot(aes(V1,V2))+
  geom_line()+
  labs(x = "km", y=expression(paste(beta(t))), title = "função de coeficiente estimado")
```

```{r}
par(mfrow=c(3,3))

beta_fn_hat0 <- beta_fn_hat  # saving beta(t) from fPCA approach

fit <- pfr(Y ~ lf(X, k = 10, bs = "cr"), method = "REML", data = myDat)
coef <- coef(fit)
beta_fn_hat <- coef$value

for(i in 1:3){
  ind <- sel.crv[i]
  demeaned <- fpca_res$Yhat[ind,]-as.vector(fpca_res$mu)
  
  matplot(kms, t(fpca_res$Yhat[sel.crv,]-t(matrix(rep(fpca_res$mu,3), nrow=10))), 
          type='l', lwd=2, lty=1, col = 'light grey',
          xlab="miles", ylab="speed (demeaned)", main="")
  lines(kms, demeaned, type='l', lwd=2, col='red')
  
  
  plot(kms, beta_fn_hat, type='l', lwd=2,
       xlab="miles", ylab = "estimated coefficient fn", main="")
  plot(kms, demeaned*beta_fn_hat,type='l', lwd=2, col='blue',
       xlab="miles", ylab = "", main=round(mean(demeaned*beta_fn_hat), 2)) 
}

```

```{r}
par(mfrow=c(1,1))
plot( rowSums( sapply(1:2, function(a) (t(efn) %*% beta_fn_hat/10)[a] * efn[,a]) ) , type='l', lwd=2, col = "red", ylab="", xlab="miles")
lines(kms, beta_fn_hat0, type='l', lwd=2)
```

O comando `plot(fit)` plota a função de coeficientes estimada com intervalo de confiança ponto a ponto, o que NÃO é útil para inferência! Uma possível maneira de construir um intervalo de confiança conjunto é por meio do método de bootstrap.

```{r}
fpca_res <- fpca.face(X ,pve = 0.97, argvals = kms, knots = 6)
Xhat <- fpca_res$Yhat
Yhat <- predict(fit, newdata = list(X = Xhat))

# goodness-of-fit
par(mfrow=c(1,1))
plot(Y, Yhat, cex=0.5, ylab="Fitted", xlab="Observed")
abline(a = 0, b = 1)

Rsq = 1-sum((Y- as.vector(Yhat))^2)/sum((Y - mean(Y))^2)
Rsq

```

A função pfr é flexível para adicionar mais de uma covariável funcional e/ou escalar; por exemplo, `pfr(Y ~ X0 + lf(X1) + lf(X2))` para ajustar.

$$
Y_i = \mu_Y + \beta_0 X_0 + \int X_{1i}(t) \beta_1(t) dt + \int X_{2i}(t) \beta_2(t) dt + \epsilon_i.
$$

Além disso, também pode ser usado para ajustar regressão funcional não linear,

$$
Y_i = \mu_Y + \int F\{X_i(t), t\} dt + \epsilon_i.
$$

onde $F(\cdot,\cdot)$ é uma função suave bivariada desconhecida;

```{r}
#fit <- pfr(Y ~ af(X, k = c(10, 8), bs = "cr"))

fit <- pfr(Y ~ af(X, k = c(10, 8), bs = "cr"))
coef <- coef(fit)

plot(fit$fitted.values,Y)
abline(a = 0, b = 1)
```

## 3 Regressão de Função em Escalar (FoS)

A regressão de função em escalar (FoS) é uma abordagem estatística que lida com a relação entre uma função e uma variável escalar. Nesse tipo de análise, a variável de interesse é uma função contínua ao longo de uma dimensão, como o tempo, enquanto a variável preditora é uma única medida numérica.

A FoS tem várias aplicações em diferentes campos, como medicina, economia, ecologia e engenharia. Por exemplo, na medicina, pode ser usado para estudar a relação entre o perfil de expressão gênica (função) e uma variável clínica (escalar), como a gravidade de uma doença.

Uma das principais vantagens da FoS é que ela permite modelar a relação entre a função e a variável escalar de forma flexível, capturando padrões complexos e não lineares. Isso é especialmente útil quando a relação entre as duas variáveis é esperada para variar ao longo da dimensão da função.

Existem várias abordagens e métodos para realizar a regressão de função em escalar, incluindo o uso de bases funcionais, como splines, wavelets e Fourier, além de técnicas específicas, como regressão de spline penalizada e modelos de mistura.

Em resumo, a regressão de função em escalar é uma ferramenta poderosa para explorar e modelar a relação entre funções e variáveis escalares, permitindo uma análise mais detalhada e flexível dos dados em várias áreas de estudo.

Neste estudo, serão utilizados dados meteorológicos do Canadá para fins de análise.

```{r}
data("CanadianWeather")

# Temperature data
daily_avg_temp <- 
    CanadianWeather$dailyAv %>% 
    as_tibble() %>% 
    dplyr::select(contains("Temperature")) %>% 
    janitor::clean_names()


# temperature plot
daily_avg_temp %>% 
  mutate(
    day = 1:365
  ) %>% 
  pivot_longer(cols = contains("Temperature")) %>% 
  group_by(day) %>% 
  ggplot(aes(day,value, group = name, color = name)) + 
  geom_line()+
  theme(
    legend.position = "none"
  )

# precipitation data
daily_avg_prec <-
      CanadianWeather$dailyAv %>% 
      as_tibble() %>% 
      dplyr::select(contains("Precipitation")) %>% 
      janitor::clean_names()

# precipitation plot
daily_avg_prec %>% 
  mutate(
    day = 1:365
  ) %>% 
  pivot_longer(cols = contains("Precipitation")) %>% 
  group_by(day) %>% 
  ggplot(aes(day,value, group = name, color = name)) + 
  geom_line()+
  theme(
    legend.position = "none"
  )
 


# Total avg data 
total_avg_prec <- 
  daily_avg_prec %>% 
  pivot_longer(
    cols = contains("Precipitation")
    ) %>% 
  group_by(fct_inorder(name)) %>% 
  summarise(
    avg_mm = sum(value)
  ) %>% 
  rename(
    name = `fct_inorder(name)`
  ) %>% 
  mutate(
     name = str_remove(name,"_precipitation_mm")
   ) 


# Total avg plot 
total_avg_prec %>% 
  ggplot(aes(fct_inorder(name),avg_mm))+
  geom_point()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  ylim(0,max(total_avg_prec$avg_mm))
```

Questão de interesse: Qual é a associação entre a precipitação anual total e a curva de temperatura diária?

Podemos usar um modelo de regressão de função em escalar para responder a essa pergunta:

$$
Temp_i(t) = \beta_0(t) + \beta_1(t) \cdot TotalPreci + \epsilon_i(t)
$$

Primeiro, definimos nossa variável de resposta e nossa variável preditora.

```{r}
day <- 1:365

Y <- 
  daily_avg_temp %>% 
  as.matrix() %>% 
  t()

X <-
  total_avg_prec %>% 
  dplyr::select(-name) %>% 
  as_vector()

myDat <- data.frame(X = X, Y= Y)

dim(Y);length(X)
```

E ajustamos o modelo de regressão de função em escalar usando a função `pffr`. (A função `pffr` no pacote refund pode ajustar qualquer modelo linear funcional com resposta funcional.)

```{r, warning=FALSE}

fit <- pffr(Y ~ X, data = myDat)
yhat <- predict(fit, newdata = myDat) 
  

Rsq_t <- 1-colSums((Y - yhat)^2) / colSums((Y - colMeans(Y))^2)
mean(Rsq_t)
```

```{r, warning=FALSE}
y_pivot <- Y %>% 
  t() %>% 
  as_tibble() %>% 
  mutate(
    day = 1:365
  ) %>% 
  pivot_longer(cols = contains("_c"), values_to = "true_value", names_to = "station")


yhat_pivot <- yhat %>% 
  t() %>% 
  as_tibble() %>% 
  pivot_longer(cols = contains("V"), values_to = "fitted", names_to = "station_fitted")


tibble(y_pivot, yhat_pivot) %>% 
  group_by(day) %>% 
  ggplot(aes(day, true_value, group = station))+
  geom_line(color = "gray")+
  geom_line(aes(day, fitted, group = station_fitted, color = station_fitted))+
  theme(
    legend.position = "none"
  )
```

A função de coeficientes estimados é:

```{r}
coef <- coef(fit)
beta0.hat <- coef$smterms$`Intercept(yindex)`$coef
beta1.hat <- coef$smterms$`X(yindex)`$coef

tibble(index = beta0.hat$yindex.vec, value = beta0.hat$value) %>% 
  ggplot(aes(index,value))+
  geom_line()+
  labs(x = "day", y = expression(paste(beta[0](t))), title = "")


tibble(index = beta1.hat$yindex.vec, value = beta1.hat$value)%>% 
  ggplot(aes(index,value))+
  geom_line()+
  labs(x = "day", y = expression(paste(beta[1](t))), title = "")
```

Outras funções que podem ajustar regressão de função em escalar são bayes_fosr e fosr no pacote refund e fRegress no pacote fda. Note que a seleção dos parâmetros de suavização não está implementada na função fRegress. Enquanto isso, fosr pode receber tanto uma matriz como um objeto fd do pacote fda, além de poder selecionar parâmetros de suavização ótimos usando diversos métodos, como `GCV`, `REML`, `ML`, entre outros (`?fosr`).

`bayes_fosr` utiliza estimação Bayesiana e `plot_shiny` recebe a saída de `bayes_fosr` para plotagens interativas.

```{r}
#fit <- bayes_fosr(Y ~ X)
#plot_shiny(fit)
```

Isso retorna cinco abas com gráficos interativos:

Aba 1: Dados Observados (resposta observada colorida com base na covariável selecionada pelo usuário.)

1)  Aba 2: Valores Ajustados (curvas previstas com diferentes valores da covariável)

2)  Aba 3: Funções de Coeficientes (funções de coeficientes estimadas)

3)  Aba 4: Resíduos (curvas de resíduos coloridas com base em sua profundidade)

(Atividade em grupo) Explore os gráficos interativos.

## 4 Regressão de função em função (FoF) - Modelo Concorrente

A regressão de função em função (FoF) é uma abordagem estatística que permite modelar a relação entre duas funções contínuas ao longo de uma dimensão comum. No contexto do modelo concorrente, a FoF é usada para investigar a relação entre uma função resposta e uma função preditora, ambas observadas na mesma dimensão temporal.

No modelo concorrente, a função resposta é modelada como uma combinação linear das funções preditoras, ponderadas por coeficientes de regressão desconhecidos. Esses coeficientes indicam como a função resposta é influenciada pelas diferentes características da função preditora.

Para ajustar o modelo FoF concorrente, são utilizadas técnicas estatísticas como mínimos quadrados parciais ou máxima verossimilhança. O objetivo é estimar os coeficientes de regressão para descrever a relação entre as funções resposta e preditora.

O modelo FoF concorrente pode ser aplicado em várias áreas, como ciências ambientais, medicina, economia e engenharia, onde existem dados funcionais coletados ao longo do tempo. Ele fornece uma abordagem flexível para modelar a complexa relação funcional entre duas variáveis observadas em uma dimensão comum.

O modelo de regressão funcional concorrente

$$
Temp_i(t) = \beta_0(t) + \beta_1(t) \cdot Preci(t) + \epsilon_i(t)
$$

relaciona a temperatura média diária no ponto de tempo atual t com a precipitação média diária no mesmo ponto de tempo t.

```{r}
data("CanadianWeather")

day <- 1:365
# selecionando os dados de temperatura de todas as estações - 365 dias
Y <- t(as.matrix(CanadianWeather$dailyAv[,,1]))
# criando Fpca com os dados de precipitação
fit <- fpca.sc(t(as.matrix(CanadianWeather$dailyAv[,,2])), pve=0.99)
#selecionando os dados ajustados criados pela Fpca
X <- fit$Yhat 


myDat <- list()
myDat$X <- X
myDat$Y <- Y

# Criando um modelo de regressão usando pffr function
fit <- pffr(Y ~ X, data = myDat)
yhat <- predict(fit, newdata = myDat)
Rsq_t <- 1-colSums((Y - yhat)^2) / colSums((Y - colMeans(Y))^2)
mean(Rsq_t) # erro médio quadratico
```

Este modelo explica cerca de 77% da variabilidade total. As funções de coeficiente estimadas são:

```{r}
coef <- coef(fit)
beta0.hat <- coef$smterms$`Intercept(yindex)`$coef
beta1.hat <- coef$smterms$`X(yindex)`$coef



tibble(index = beta0.hat$yindex.vec, value = beta0.hat$value) %>% 
  ggplot(aes(index,value))+
  geom_line()+
  labs(x = "day", y = expression(paste(beta[0](t))), title = "")


tibble(index = beta1.hat$yindex.vec, value = beta1.hat$value)%>% 
  ggplot(aes(index,value))+
  geom_line()+
  labs(x = "day", y = expression(paste(beta[1](t))), title = "")
```

A função `fRegress` no pacote fda também ajusta a regressão funcional concorrente, mas a seleção dos parâmetros de suavização não está implementada na função.

Resumo: - Regressão escalar em função - Dados de maratona - Gráficos interativos (plot_shiny) - Regressão de função em escalar e regressão de função em função - Dados meteorológicos do Canadá - Precipitação média como covariável escalar - Precipitação e temperatura como função de localização

Atividades em grupo e individuais: - Analise os dados de DTI usando os modelos de regressão que aprendemos hoje. - Qual é a associação entre os perfis de FA e as pontuações de PASAT de pacientes com esclerose múltipla em sua primeira visita? (regressão escalar em função) - O conjunto de dados também inclui rcst - perfis de FA coletados do trato corticospinal direito. Como essas medidas se relacionam com as medidas de FA ao longo de CCA? - Ajuste um modelo linear funcional com FA ao longo de CCA como resposta e pontuações de PASAT como covariável; experimente diferentes funções R. Discuta os gráficos interativos dos resultados da regressão de função em escalar.

Vamos usar o conjunto de dados DTI para ilustrar dados funcionais observados longitudinalmente amanhã. Tente plotar vários perfis observados de um paciente com EM selecionado aleatoriamente. (Atividade individual)
